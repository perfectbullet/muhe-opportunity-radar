"""
LangGraph æ•°æ®åˆ†æå·¥ä½œæµ
æ•´åˆæ–‡æ¡£è§£æã€æŒ‡æ ‡è®¡ç®—ã€AI åˆ†æçš„å®Œæ•´æµç¨‹
"""

from typing import Dict, Any, TypedDict
from typing_extensions import Annotated
import logging

logger = logging.getLogger(__name__)

# æ£€æŸ¥ LangGraph æ˜¯å¦å¯ç”¨
try:
    from langgraph.graph import StateGraph, END
    LANGGRAPH_AVAILABLE = True
except ImportError:
    LANGGRAPH_AVAILABLE = False
    logger.warning("âš ï¸  LangGraph æœªå®‰è£…ï¼Œè¯·è¿è¡Œ: pip install langgraph")


# å®šä¹‰å·¥ä½œæµçŠ¶æ€
class AnalysisState(TypedDict):
    """åˆ†æå·¥ä½œæµçš„çŠ¶æ€å®šä¹‰"""
    # è¾“å…¥
    document_id: str                    # æ–‡æ¡£ IDï¼ˆå¯é€‰ï¼‰
    material: str                        # ç›´æ¥æä¾›çš„ææ–™ï¼ˆå¯é€‰ï¼‰
    investor_id: str                     # æŠ•èµ„è€… ID
    llm_provider: str                    # LLM æä¾›å•†
    additional_context: str              # é¢å¤–ä¸Šä¸‹æ–‡
    
    # ä¸­é—´ç»“æœ
    parsed_data: Dict[str, Any]          # è§£æåçš„æ•°æ®
    calculated_metrics: Dict[str, Any]   # è®¡ç®—çš„æŒ‡æ ‡
    analysis_result: str                 # AI åˆ†æç»“æœ
    investor_info: Dict[str, Any]        # æŠ•èµ„è€…ä¿¡æ¯
    
    # æœ€ç»ˆè¾“å‡º
    final_report: Dict[str, Any]         # æœ€ç»ˆæŠ¥å‘Š
    
    # å…ƒæ•°æ®
    error: str                           # é”™è¯¯ä¿¡æ¯
    completed_at: str                    # å®Œæˆæ—¶é—´


class DataAnalysisWorkflow:
    """æ•°æ®åˆ†æå·¥ä½œæµ - åŸºäº LangGraph"""
    
    def __init__(self, llm_provider: str = "siliconflow"):
        """
        åˆå§‹åŒ–å·¥ä½œæµ
        
        Args:
            llm_provider: LLM æä¾›å•†ï¼ˆsiliconflow/deepseek/qwen ç­‰ï¼‰
        """
        if not LANGGRAPH_AVAILABLE:
            raise ImportError("éœ€è¦å®‰è£… LangGraph: pip install langgraph")
        
        self.llm_provider = llm_provider
        self.workflow = self._build_workflow()
    
    def _build_workflow(self) -> StateGraph:
        """
        æ„å»ºå·¥ä½œæµå›¾
        
        æµç¨‹: è§£æ â†’ è®¡ç®— â†’ åˆ†æ â†’ æ±‡æ€»
        """
        from analysis.nodes.parse_node import parse_document_node_sync
        from analysis.nodes.calculate_node import calculate_metrics_node
        from analysis.nodes.analyze_node import llm_analyze_node
        from analysis.nodes.summarize_node import summarize_node
        
        # åˆ›å»ºçŠ¶æ€å›¾
        workflow = StateGraph(AnalysisState)
        
        # æ·»åŠ èŠ‚ç‚¹
        workflow.add_node("parse", parse_document_node_sync)
        workflow.add_node("calculate", calculate_metrics_node)
        workflow.add_node("analyze", llm_analyze_node)
        workflow.add_node("summarize", summarize_node)
        
        # å®šä¹‰è¾¹ï¼ˆæµç¨‹è¿æ¥ï¼‰
        workflow.add_edge("parse", "calculate")
        workflow.add_edge("calculate", "analyze")
        workflow.add_edge("analyze", "summarize")
        workflow.add_edge("summarize", END)
        
        # è®¾ç½®å…¥å£ç‚¹
        workflow.set_entry_point("parse")
        
        # ç¼–è¯‘å·¥ä½œæµ
        app = workflow.compile()
        
        logger.info("âœ“ LangGraph å·¥ä½œæµå·²æ„å»º")
        return app
    
    def run(
        self,
        material: str,
        investor_id: str = "buffett",
        document_id: str = None,
        additional_context: str = None
    ) -> Dict[str, Any]:
        """
        æ‰§è¡Œå®Œæ•´çš„åˆ†æå·¥ä½œæµï¼ˆåŒæ­¥ç‰ˆæœ¬ï¼‰
        
        Args:
            material: åˆ†æææ–™æ–‡æœ¬
            investor_id: æŠ•èµ„è€… ID
            document_id: æ–‡æ¡£ IDï¼ˆå¯é€‰ï¼‰
            additional_context: é¢å¤–ä¸Šä¸‹æ–‡
            
        Returns:
            åŒ…å« final_report çš„ç»“æœå­—å…¸
        """
        # åˆå§‹åŒ–çŠ¶æ€
        initial_state = {
            "document_id": document_id,
            "material": material,
            "investor_id": investor_id,
            "llm_provider": self.llm_provider,
            "additional_context": additional_context,
            "parsed_data": None,
            "calculated_metrics": None,
            "analysis_result": None,
            "investor_info": None,
            "final_report": None,
            "error": None,
            "completed_at": None
        }
        
        try:
            # æ‰§è¡Œå·¥ä½œæµ
            logger.info(f"ğŸš€ å¼€å§‹æ‰§è¡Œåˆ†æå·¥ä½œæµ (æŠ•èµ„è€…: {investor_id})")
            result = self.workflow.invoke(initial_state)
            
            # æ£€æŸ¥æ˜¯å¦æœ‰é”™è¯¯
            if result.get("error"):
                logger.error(f"å·¥ä½œæµæ‰§è¡Œå‡ºé”™: {result['error']}")
            else:
                logger.info("âœ… å·¥ä½œæµæ‰§è¡Œå®Œæˆ")
            
            return result
            
        except Exception as e:
            logger.error(f"å·¥ä½œæµæ‰§è¡Œå¤±è´¥: {str(e)}")
            return {
                **initial_state,
                "error": str(e),
                "final_report": None
            }
    
    async def run_async(
        self,
        material: str,
        investor_id: str = "buffett",
        document_id: str = None,
        additional_context: str = None
    ) -> Dict[str, Any]:
        """
        æ‰§è¡Œå®Œæ•´çš„åˆ†æå·¥ä½œæµï¼ˆå¼‚æ­¥ç‰ˆæœ¬ï¼‰
        
        Args:
            material: åˆ†æææ–™æ–‡æœ¬
            investor_id: æŠ•èµ„è€… ID
            document_id: æ–‡æ¡£ IDï¼ˆå¯é€‰ï¼‰
            additional_context: é¢å¤–ä¸Šä¸‹æ–‡
            
        Returns:
            åŒ…å« final_report çš„ç»“æœå­—å…¸
        """
        import asyncio
        
        # åœ¨çº¿ç¨‹æ± ä¸­æ‰§è¡ŒåŒæ­¥å·¥ä½œæµ
        result = await asyncio.to_thread(
            self.run,
            material=material,
            investor_id=investor_id,
            document_id=document_id,
            additional_context=additional_context
        )
        
        return result


# ä¾¿æ·å‡½æ•°
def create_workflow(llm_provider: str = "siliconflow") -> DataAnalysisWorkflow:
    """
    åˆ›å»ºå·¥ä½œæµå®ä¾‹çš„ä¾¿æ·å‡½æ•°
    
    Args:
        llm_provider: LLM æä¾›å•†
        
    Returns:
        DataAnalysisWorkflow å®ä¾‹
    """
    return DataAnalysisWorkflow(llm_provider=llm_provider)


if __name__ == "__main__":
    # æµ‹è¯•ä»£ç 
    print("LangGraph æ•°æ®åˆ†æå·¥ä½œæµ")
    
    if LANGGRAPH_AVAILABLE:
        # åˆ›å»ºå·¥ä½œæµ
        workflow = create_workflow()
        
        # æµ‹è¯•ææ–™
        test_material = """
        å…¬å¸ï¼šè´µå·èŒ…å°
        å¸‚ç›ˆç‡ï¼š35å€
        å¸‚å‡€ç‡ï¼š12å€
        ROEï¼š30%
        è¥æ”¶å¢é•¿ï¼š15%
        æ¯›åˆ©ç‡ï¼š92%
        """
        
        # æ‰§è¡Œå·¥ä½œæµ
        result = workflow.run(
            material=test_material,
            investor_id="buffett"
        )
        
        if result.get("final_report"):
            print("\n" + "="*50)
            print(result["final_report"]["markdown"])
        else:
            print(f"æ‰§è¡Œå¤±è´¥: {result.get('error')}")
    else:
        print("è¯·å…ˆå®‰è£… LangGraph: pip install langgraph")
