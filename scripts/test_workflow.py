"""
æµ‹è¯• LangGraph å·¥ä½œæµå’Œæ–‡æ¡£è§£æåŠŸèƒ½
"""

import sys
from pathlib import Path

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°è·¯å¾„
sys.path.insert(0, str(Path(__file__).parent.parent))

from analysis.graph_workflow import DataAnalysisWorkflow, LANGGRAPH_AVAILABLE
from analysis.document_parser import DocumentParser


def test_document_parser():
    """æµ‹è¯•æ–‡æ¡£è§£æå™¨"""
    print("="*60)
    print("æµ‹è¯• 1: æ–‡æ¡£è§£æå™¨")
    print("="*60)
    
    parser = DocumentParser()
    print(f"å¯ç”¨è§£æå™¨: {parser.available_parsers}")
    print(f"æ”¯æŒæ ¼å¼: {DocumentParser.get_supported_formats()}")
    print()


def test_workflow():
    """æµ‹è¯• LangGraph å·¥ä½œæµ"""
    print("="*60)
    print("æµ‹è¯• 2: LangGraph å·¥ä½œæµ")
    print("="*60)
    
    if not LANGGRAPH_AVAILABLE:
        print("âš ï¸  LangGraph æœªå®‰è£…ï¼Œè·³è¿‡å·¥ä½œæµæµ‹è¯•")
        print("è¯·è¿è¡Œ: pip install langgraph")
        return
    
    # æµ‹è¯•ææ–™
    test_material = """
    å…¬å¸ï¼šè´µå·èŒ…å°
    è¡Œä¸šï¼šç™½é…’åˆ¶é€ 
    
    è´¢åŠ¡æŒ‡æ ‡ï¼š
    - å¸‚ç›ˆç‡ï¼ˆPEï¼‰ï¼š35å€
    - å¸‚å‡€ç‡ï¼ˆPBï¼‰ï¼š12å€
    - å‡€èµ„äº§æ”¶ç›Šç‡ï¼ˆROEï¼‰ï¼š30%
    - è¥æ”¶å¢é•¿ç‡ï¼š15%
    - æ¯›åˆ©ç‡ï¼š92%
    - è‚¡æ¯ç‡ï¼š1.2%
    
    åŸºæœ¬é¢ï¼š
    èŒ…å°ä½œä¸ºä¸­å›½ç™½é…’è¡Œä¸šçš„é¾™å¤´ä¼ä¸šï¼Œå…·æœ‰å¼ºå¤§çš„å“ç‰ŒæŠ¤åŸæ²³å’Œå®šä»·æƒã€‚
    å…¬å¸ç°é‡‘æµå……æ²›ï¼Œè´Ÿå€ºç‡ä½ï¼Œç®¡ç†å±‚ç¨³å¥ã€‚
    """
    
    print("æµ‹è¯•ææ–™:")
    print(test_material)
    print("\n" + "="*60)
    
    try:
        # åˆ›å»ºå·¥ä½œæµ
        workflow = DataAnalysisWorkflow(llm_provider="siliconflow")
        print("âœ“ å·¥ä½œæµåˆ›å»ºæˆåŠŸ")
        
        # æ‰§è¡Œå·¥ä½œæµ
        print("\nğŸš€ å¼€å§‹æ‰§è¡Œå·¥ä½œæµ...")
        result = workflow.run(
            material=test_material,
            investor_id="buffett"
        )
        
        print("\n" + "="*60)
        print("æ‰§è¡Œç»“æœ:")
        print("="*60)
        
        # æ˜¾ç¤ºé”™è¯¯ï¼ˆå¦‚æœæœ‰ï¼‰
        if result.get("error"):
            print(f"âŒ é”™è¯¯: {result['error']}")
        
        # æ˜¾ç¤ºè®¡ç®—çš„æŒ‡æ ‡
        if result.get("calculated_metrics"):
            metrics = result["calculated_metrics"].get("metrics", {})
            summary = result["calculated_metrics"].get("summary", {})
            
            print("\nğŸ“Š æå–çš„è´¢åŠ¡æŒ‡æ ‡:")
            for key, value in metrics.items():
                if value is not None:
                    print(f"  - {key}: {value}")
            
            print(f"\nä¼°å€¼è¯„ä¼°: {summary.get('valuation', 'N/A')}")
            print(f"ä¼ä¸šè´¨é‡: {summary.get('quality', 'N/A')}")
        
        # æ˜¾ç¤ºæœ€ç»ˆæŠ¥å‘Š
        if result.get("final_report"):
            print("\n" + "="*60)
            print("ğŸ“„ æœ€ç»ˆæŠ¥å‘Š:")
            print("="*60)
            print(result["final_report"]["markdown"])
        
        print("\nâœ… å·¥ä½œæµæµ‹è¯•å®Œæˆ")
        
    except Exception as e:
        print(f"\nâŒ å·¥ä½œæµæ‰§è¡Œå¤±è´¥: {str(e)}")
        import traceback
        traceback.print_exc()


def test_metrics_extraction():
    """æµ‹è¯•æŒ‡æ ‡æå–åŠŸèƒ½"""
    print("\n" + "="*60)
    print("æµ‹è¯• 3: æŒ‡æ ‡æå–")
    print("="*60)
    
    from analysis.nodes.calculate_node import calculate_metrics_node
    
    test_state = {
        "parsed_data": {
            "raw_text": """
            PEï¼š25å€
            PBï¼š3.5
            ROEï¼š20%
            è¥æ”¶å¢é•¿ï¼š18%
            æ¯›åˆ©ç‡ï¼š45%
            """
        }
    }
    
    result = calculate_metrics_node(test_state)
    
    if result.get("calculated_metrics"):
        metrics = result["calculated_metrics"]["metrics"]
        print("æå–çš„æŒ‡æ ‡:")
        for key, value in metrics.items():
            if value is not None:
                print(f"  - {key}: {value}")
        
        print(f"\nPEG æ¯”ç‡: {metrics.get('peg_ratio', 'N/A')}")
        print(f"ä¼°å€¼è¯„ä¼°: {result['calculated_metrics']['summary']['valuation']}")
        print(f"ä¼ä¸šè´¨é‡: {result['calculated_metrics']['summary']['quality']}")
    else:
        print(f"âŒ æŒ‡æ ‡æå–å¤±è´¥: {result.get('error')}")


if __name__ == "__main__":
    print("\nğŸ§ª å¼€å§‹æµ‹è¯• LangGraph å·¥ä½œæµå’Œæ–‡æ¡£è§£æåŠŸèƒ½\n")
    
    # è¿è¡Œæµ‹è¯•
    test_document_parser()
    test_metrics_extraction()
    test_workflow()
    
    print("\n" + "="*60)
    print("æµ‹è¯•å®Œæˆ")
    print("="*60)
